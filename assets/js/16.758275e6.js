(window.webpackJsonp=window.webpackJsonp||[]).push([[16],{496:function(s,t,a){"use strict";a.r(t);var n=a(4),e=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p",[s._v(":::tips\n以下内容绝大部分摘于《MySql InnoDB技术内幕》第2版，姜承尧著。\n:::")]),s._v(" "),a("h2",{attrs:{id:"innodb体系架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#innodb体系架构"}},[s._v("#")]),s._v(" InnoDB体系架构")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("如图所示，InnoDB有多个内存块（组成内存池）。其主要职责如下：\n"),a("ul",[a("li",[s._v("维护所有进程/线程需要访问的多个内部数据结构")]),s._v(" "),a("li",[s._v("缓存磁盘上的数据，方便快速读取，同时在对磁盘数据进行写操作前在内存块里做缓存操作")]),s._v(" "),a("li",[s._v("重做日志（redo log）缓冲")]),s._v(" "),a("li",[s._v("........")])])])]),s._v(" "),a("img",{staticStyle:{zoom:"40%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/innoDB/indb01.png",alt:"innoDB架构图"}}),s._v(" "),a("h3",{attrs:{id:"后台线程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#后台线程"}},[s._v("#")]),s._v(" 后台线程")]),s._v(" "),a("hr"),s._v(" "),a("h4",{attrs:{id:"master-thread"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#master-thread"}},[s._v("#")]),s._v(" Master Thread")]),s._v(" "),a("ul",[a("li",[s._v("Master Thread是一个非常核心的线程，主要负责将缓冲池中的数据异步刷新到磁盘，**保证数据的一致性。**包括脏页缓冲、合并插入（INSERT BUFFER）、UNDO页的回收")])]),s._v(" "),a("h4",{attrs:{id:"io-thread"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#io-thread"}},[s._v("#")]),s._v(" IO Thread")]),s._v(" "),a("ul",[a("li",[s._v("在InnoDB存储引擎大量使用AIO（异步非阻塞IO）来处理写IO请求。而AIO的实现基于事件回调方式，因此InnoDB提供了**四种IO。**write、read、insert buffer、log。")]),s._v(" "),a("li",[s._v("查看读写io线程数量："),a("strong",[s._v("show variables like 'innodb_%io_threads';")])])]),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/innoDB/indb02.jpg"}}),s._v(" "),a("ul",[a("li",[s._v("查看io threads详情 : "),a("strong",[s._v("show engine innodb status;")]),s._v(" "),a("ul",[a("li",[s._v("如下图，可以看到线程编号以及线程的类型。")])])])]),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/innoDB/indb03.png"}}),s._v(" "),a("ul",[a("li",[s._v("之后可以通过innodb_read_io_threads以及innodb_write_io_threads设置读写线程的数量。")])]),s._v(" "),a("h4",{attrs:{id:"purage-thread"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#purage-thread"}},[s._v("#")]),s._v(" Purage Thread")]),s._v(" "),a("ul",[a("li",[s._v("事务提交后，其undolog可能不再需要，因此需要PurageThread来回收已经使用并分配的undo页。为了减轻master thread的负担，在innodb1.1版本以后，purage操作独立到单独的线程。")])]),s._v(" "),a("h2",{attrs:{id:"表分区的优点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#表分区的优点"}},[s._v("#")]),s._v(" 表分区的优点")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("改善大型表以及各种访问模式的的表的可伸缩性，可管理型和提高数据库效率。")]),s._v(" "),a("li",[s._v("与单个磁盘或文件系统分区相比，可以存储更多的数据。（单个磁盘和文件系统对单个文件的大小有限制，通过分区后，我们可以将不同的分区存储到不同的硬盘上）")]),s._v(" "),a("li",[s._v("方便后期维护数据库表：例如，某些历史行情数据已经没有什么价值，我们就可以通过删除分区的方式直接从磁盘上抹去这一部分历史数据，减小表的体积，改善表的性能。delete语句需要一条一条去删除，性能比较低。")]),s._v(" "),a("li",[s._v("对于开发者而言我觉得最大的优点就是合理的运用表分区"),a("font",{attrs:{color:"red"}},[a("strong",[s._v("能极大的提高查询性能")])])],1),s._v(" "),a("li",[s._v("通过跨磁盘甚至跨服务器分散查询数据，能得到更高的查询吞吐量。")]),s._v(" "),a("li",[s._v("在Mysql的5.5版本后支持所有的分区函数化")])]),s._v(" "),a("h2",{attrs:{id:"基本分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基本分区"}},[s._v("#")]),s._v(" 基本分区")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[a("strong",[s._v("RANGE分区")]),s._v("：基于一个给定连续区间的列值，把多行分配给分区。")]),s._v(" "),a("li",[a("strong",[s._v("List分区")]),s._v("：类似于RANGE分区，区别是LIST分区是基于列值匹配一个离散集合中的某个值来进行选择。")]),s._v(" "),a("li",[a("strong",[s._v("HASH分区")]),s._v(":基于用户定义的表达式返回值来进行选择的分区。表达式将要插入到表中的这些行的列值进行计算。这个函数包括MySql中有效的、返回非负整数的任意表达式。")]),s._v(" "),a("li",[a("strong",[s._v("KEY分区")]),s._v(":类似于HASH分区，区别是KEY分区只支持一列的计算，支持的数据离散分布均匀程度和数据量有所不同。")])]),s._v(" "),a("h3",{attrs:{id:"range分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#range分区"}},[s._v("#")]),s._v(" RANGE分区")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("基于一个"),a("font",{attrs:{color:"red"}},[a("strong",[s._v("给定连续区间")])]),s._v("的列值，把多行分配给分区。")],1),s._v(" "),a("li",[s._v("这些区间"),a("strong",[s._v("连续")]),s._v("且"),a("strong",[s._v("不能相互重叠")]),s._v("，可以使用VALUES、LESS、THAN操作符来定义。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n\t更新表分区语句 \n\t以下语句意思可以翻译成：\n\t将titles进行范围分区，分区条件为年份的值。\n\tp01分区代表小于1985年的数据\n\tp02分区代表大于1985小于1986的数据\n\t....\n\tp04分区代表大于1987年以上的数据\n*/")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" titles\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" range"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("year")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("from_date"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1985")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p02 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1986")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p03 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1987")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p04 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("MAXVALUE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n\t创建表时候建分区,根据age步长为10进行分区。\n\t这里要注意分区的名字是不区分大小写的！！！！ \n\t同时分区条件一定要包含主键，唯一约束列！！！！\n*/")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("45")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("`")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("NOT")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("NULL")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" range"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p02 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p03 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p04 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("MAXVALUE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br")])]),a("ul",[a("li",[s._v("然后看下查询T1表的执行计划")])]),s._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[s._v("注意第一条语句和第二条语句查询条件")]),s._v(" "),a("p",[s._v("​\t可以看到根据age字段查只会去查询p01分区的idb文件，说明他只去一个分区文件进行了IO操作")]),s._v(" "),a("p",[s._v("​\t而根据id字段查他需要查询所有分区。因此我们的sql的书写需要规范避免查询太多分区，这样就失去了分区的意义。")])]),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/partition1.jpg"}}),s._v(" "),a("hr"),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/partition1.jpg"}}),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[a("p",[s._v("分区后生成的物理文件（以T1表为例，Mysql默认存储引擎InnoDB）")]),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("​\t可以看到T1表生成的文件包含frm表结构文件和对应4个分区的ibd文件。")]),s._v(" "),a("p",[s._v("​\t那这也不难理解，为什么建分区的条件一定要有主键。现在的索引文件变了，以前的唯一列分片后不能够保证唯一。类似于分表后需要处理主键重复的问题。因此Mysql分区需要你妥协，唯一列也进行分区。")])])])]),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/partition3.jpg"}}),s._v(" "),a("h3",{attrs:{id:"list分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#list分区"}},[s._v("#")]),s._v(" LIST分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("类似于RANGE分区，区别是LIST分区是基于列值匹配一个"),a("strong",[s._v("离散集合中的某个值")]),s._v("来进行选择。")]),s._v(" "),a("p",[s._v("语法：PARTITION BY LIST(expr)")]),s._v(" "),a("p",[s._v("其中“expr”是某一列的值，或者基于某一列的值、"),a("strong",[s._v("并返回一个整数的表达式")]),s._v("。然后通过VALUES IN (value_list)来定义每个分区")]),s._v(" "),a("p",[s._v("value_list代表用逗号分割的整数列表，例如(1,2,3,4,5)。")])]),s._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",[s._v("在Mysql5.1版本使用LIST分区，默认只能匹配整数列表")]),s._v(" "),a("p",[s._v("在5.5版本后通过COLUMNS关键字可以支持字符串，日期列作为分区列。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 例子 \n\t 将T2表根据商品类别分区，类别编号为123，456，789分区到p01,p02,p03\n\t 解释：\n\t 在上文概念中提高的离散集合中的某个值，也就是说LIST分区给我们提供了更高的灵活性\n\t 假如我们对T2的类别做范围分区1-2，3-5，6-8。\n\t 突然产品经理加了个编号为10的商品，需要该商品分区到p01。\n\t 很显然RANGE这种基于连续区间的分区没法做到，\n\t 只能借助更为灵活的LIST分区。\n*/")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" T2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n cid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("comment")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'商品类别'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n pos_date "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("8")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br")])]),a("h3",{attrs:{id:"hash分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash分区"}},[s._v("#")]),s._v(" HASH分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("基于用户定义的表达式返回值来进行选择的分区。表达式将要插入到表中的这些行的列值进行计算。这个函数包括MySql中有效的、返回非负整数的任意表达式。")])]),s._v(" "),a("blockquote",[a("p",[s._v("还是用T2商品表创建HASH分区")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* HASH分区语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" T2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n cid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("comment")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'商品类别'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n pos_date "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("HASH")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\npartitions "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*根据cid分四个区 */")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("blockquote",[a("p",[s._v("不难理解通过对列值进行hash运算后进行分区，可以让数据更为均匀的分散到各个分区。")])]),s._v(" "),a("h4",{attrs:{id:"linear-hash分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#linear-hash分区"}},[s._v("#")]),s._v(" LINEAR HASH分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("线性HASH分区，同样属于HASH分区的一种。使用的是一种线性的2次幂运算法则，常规HASH使用的是求HASH函数的模数。（可以联系JAVA中的HashMap的知识点理解）。与常规的HASH分区比较：")]),s._v(" "),a("ol",[a("li",[a("p",[s._v("优点是增加，删除，合并和拆分分区将变得更快捷。有利于处理极大数量的表。(TB级)")])]),s._v(" "),a("li",[a("p",[s._v("缺点是数据分散可能不是那么均匀，容易产生”hotspot nodes“热点节点问题。由于分布不均匀可能导致某些分区访问压力过大，某些分区访问压力比较轻。")])])])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* LINEAR HASH分区语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" T2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n cid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("comment")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'商品类别'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n pos_date "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" linear "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\npartitions "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*根据cid分四个区 */")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("h3",{attrs:{id:"key-分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#key-分区"}},[s._v("#")]),s._v(" KEY 分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("使用频率不高")]),s._v(" "),a("p",[s._v("类似于HASH分区，区别是KEY分区只支持一列的计算，支持的数据离散分布均匀程度和数据量有所不同。")]),s._v(" "),a("p",[s._v("与HASH分区的区别是，HASH分区计算可以根据用户定义的表达式来分区。而KEY分区是由MySql服务器提供。本质上都是做了Hash运算。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* KEY 分区语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("create")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" T2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n cid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("comment")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'商品类别'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("varchar")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n pos_date "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("datetime")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" linear "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("key")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("cid"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\npartitions "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*根据cid分四个区 */")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("h3",{attrs:{id:"多列分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#多列分区"}},[s._v("#")]),s._v(" 多列分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",[s._v("在MySql 5.5 版本后支持多列分区，通过COLUMNS关键字允许字符串，日期作为分区定义列，同时还允许使用多个列定义一个分区")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 语法 */")]),s._v("\ncreatee "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n id "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n age "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n weight "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" range "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("columns")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("id"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("age"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 这里的多列匹配原则类似于联合索引最左匹配原则，先匹配id匹配到了就不会去匹配age */")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("34")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p02 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("54")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p03 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p04 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("MAXVALUE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("MAXVALUE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br")])]),a("h2",{attrs:{id:"高级分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高级分区"}},[s._v("#")]),s._v(" 高级分区")]),s._v(" "),a("h3",{attrs:{id:"子分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#子分区"}},[s._v("#")]),s._v(" 子分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"custom-block tip"},[a("p",[s._v("顾名思义，子分区就是对每个分区再进行分区。")]),s._v(" "),a("p",[s._v("子分区可以用于大表，在多个磁盘间分配数据和索引。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\tid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  udate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DATE")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" RANGE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("YEAR")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("udate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 对T3表按照udate的年份进行范围分区（暂成为主分区）")]),s._v("\nSUBPARTITION "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("BY")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("HASH")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("TO_DAYS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("udate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 针对以上的每个主分区再对udate的日进行HASH分区，分区数为2")]),s._v("\nSUBPARTITIONS "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" LESS THAN "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1990")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/*\n  为了优化I/O存储性能，可以将分区对应的文件分散到各个磁盘上进行存储。\n  data directory = 'disk_a/...'\n  index directory = 'disk_b/...',\n  */")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P02 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" LESS THAN "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2000")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P03 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("VALUES")]),s._v(" LESS THAN MAXVALUE\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 因此以上分区总共会生成6个分区。 ")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br")])]),a("blockquote",[a("p",[s._v("查看生成的对应文件：6个ibd文件")])]),s._v(" "),a("img",{staticStyle:{zoom:"50%"},attrs:{src:"http://image-airlin.test.upcdn.net/class/mysql/partition4.jpg"}}),s._v(" "),a("ul",[a("li",[s._v("为了优化I/O存储性能，也可以吧分区文件存储到不同的磁盘上")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 语法 */")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CREATE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T5"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\tid "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("INT")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  udate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("DATE")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ENGINE")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("MyISAM\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" range"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("year")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("udate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nsubpartition "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("hash")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("TO_DAYS"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("udate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2014")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\tsubpartition s0\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/a/data'")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/a/idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\tsubpartition s1\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/b/data'")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/b/idx'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p02 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2020")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\tsubpartition s2\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/c/data'")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/c/idx'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n\tsubpartition s3\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("data")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/d/data'")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("index")]),s._v(" directory "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/var/d/idx'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br")])]),a("blockquote",[a("p",[s._v("指定目录创建分区会在data目录下生成isl文本文件，该文件内容就是用来描述分区的data,index文件的地址。")])]),s._v(" "),a("div",{staticClass:"custom-block warning"},[a("p",{staticClass:"custom-block-title"},[s._v("注意")]),s._v(" "),a("p",[s._v("每个分区下面的子分区数量必须相同！")]),s._v(" "),a("p",[s._v("如果使用SUBPARTITION来明确定义子分区，那么需要明确定义所有分区的子分区。（指定显示创建）")]),s._v(" "),a("p",[s._v("子分区命名也是唯一的")])]),s._v(" "),a("h2",{attrs:{id:"分区管理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分区管理"}},[s._v("#")]),s._v(" 分区管理")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[a("strong",[s._v("更新分区")])])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 表名")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("by")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("-- 和创建分区语法相同 ")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("h3",{attrs:{id:"range-list分区管理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#range-list分区管理"}},[s._v("#")]),s._v(" Range&List分区管理")]),s._v(" "),a("ul",[a("li",[s._v("值得注意的是删除分区同时间会删除分区里的所有数据。如果仅仅只是为了抹去数据，一般建议使用TRUNCATE语句。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("drop")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("truncate")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p02"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("ul",[a("li",[a("strong",[s._v("新增分区")])])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("add")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--RANGE")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("add")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--LIST")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("div",{staticClass:"custom-block warning"},[a("ol",[a("li",[s._v("对于RANGE新增分区，只能从高端去加。")])]),s._v(" "),a("p",[s._v("例：如果某表原来根据年龄分区{(0,20),(21,30),(31,40)}分区")]),s._v(" "),a("p",[s._v("现在想新增分区那么只能从41开始新增分区，破坏了原来分区的定义，因为低端区的数据已经存放到对应的分区文件中。")]),s._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[s._v("同样对于LIST分区为了不破坏原来分区定义同样新增分区不能包含现有分区的列值条件。")])])]),s._v(" "),a("ul",[a("li",[a("strong",[s._v("分区重组（PEORGANIZE）")])])]),s._v(" "),a("blockquote",[a("p",[s._v("使用PEORGANIZE可以对现有分区进行重组，将一个分区拆分成几个分区，或者将几个分区组成一个分区")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--拆分区")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" PEORGANIZE "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("NTO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" s0 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" s1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("--分区合并")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" PEORGANIZE "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("|")]),s._v("NTO"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n\t"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" p01 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("values")]),s._v(" less than "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("div",{staticClass:"custom-block warning"},[a("p",[s._v("值得注意的是分区的重组，新的分区条件需要覆盖原有分区，同时不能有重叠部份。")]),s._v(" "),a("p",[s._v("例如上述语句，分区合并需要覆盖s0,s1分区条件。")]),s._v(" "),a("p",[s._v("而对于LIST分区，对应分区条件不能够某两个分区条件离散值重叠。")])]),s._v(" "),a("h3",{attrs:{id:"hash-key分区管理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hash-key分区管理"}},[s._v("#")]),s._v(" HASH&KEY分区管理")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("对于HASH和KEY分区，可以使用COALESCE缩减分区数量，ALTER ... ADD PARTITION增加分区数量")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" t2 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("coalesce")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("alter")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("table")]),s._v(" t2 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("add")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("partition")]),s._v(" partitions "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("h2",{attrs:{id:"分区维护"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分区维护"}},[s._v("#")]),s._v(" 分区维护")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("整理分区碎片\n"),a("ul",[a("li",[s._v("抽取分区数据保存临时表，然后删除分区里面数据，然后再插入回去")]),s._v(" "),a("li",[s._v("IO消耗很大")])])])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T1 REBUILD "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h2",{attrs:{id:"优化分区（optimize）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优化分区（optimize）"}},[s._v("#")]),s._v(" 优化分区（OPTIMIZE）")]),s._v(" "),a("hr"),s._v(" "),a("ul",[a("li",[s._v("对于经常进行修改和删除的分区，会产生较多的碎片。")])]),s._v(" "),a("div",{staticClass:"language-sql line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("OPTIMIZE")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("ul",[a("li",[s._v("以上语句主要用来回收没有使用的空间，并整理分区数据文件中的分区碎片。其IO消耗相比REBUILD小一点。")])]),s._v(" "),a("h2",{attrs:{id:"检查与修复分区"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#检查与修复分区"}},[s._v("#")]),s._v(" 检查与修复分区")]),s._v(" "),a("hr"),s._v(" "),a("div",{staticClass:"language-SQL line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("CHECK")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("ALTER")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("TABLE")]),s._v(" T1 REPAIR "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("PARTITION")]),s._v(" P1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("P3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);